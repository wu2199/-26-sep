1
WatME: Towards Lossless Watermarking Through Lexical Redundancy
Authors: Liang Chen, Yatao Bian, et al.
Conference: ACL 2024
Link: [https://arxiv.org/abs/2311.09832v3](https://arxiv.org/abs/2311.09832v3)
Code: [https://github.com/ChanLiang/WatME](https://github.com/ChanLiang/WatME)

---

Motivation

* Text generated by LLMs is often indistinguishable from human-written text, requiring watermarking to ensure detectability.
* Traditional watermarking methods (e.g., Vanilla Watermark) can degrade text quality, especially in knowledge recall and reasoning tasks.
* The goal of WatME is to achieve lossless watermarking: embedding detectable signals while preserving generation quality.

---

Upper Bound Analysis (Performance Bottlenecks)

* Unlike images, text lacks redundancy, making lossless watermarking challenging.
* Vanilla methods often assign all semantically related words to the red list, damaging generation quality.
* Higher-level emergent abilities such as reasoning and knowledge answering are more vulnerable to watermarking noise than simple fluency.

---

Why Lexical Redundancy

* LLM vocabularies contain synonym clusters, e.g., ocean vs. sea.
* WatME distributes words in such clusters mutually exclusively between red/green lists, preventing entire semantic groups from being blocked.
* This retains lexical diversity during generation and improves model expressiveness.
￼<img width="351" height="291" alt="Question" src="https://github.com/user-attachments/assets/84961368-4c72-4d11-9d18-8df6270fa3f2" />

---

Method

Lexical Redundancy Construction

* Build synonym clusters (redundancy groups):

  * Dictionary-based: WordNet, Youdao, etc.
  * Prompt-based: Using LLMs like Llama2 for synonym mining.
  * Ensures semantic/grammatical consistency and addresses subword tokenization issues.

Core Algorithm

* Two-stage construction of green/red lists:

  * Stage 1: Apply the Mutual Exclusion Rule within synonym clusters.
  * Stage 2: Regular assignment for remaining vocabulary.
* During decoding, logits of green list words are biased by δ to guide sampling.

Mathematical Definition and Theory

* Semantic Entropy: measures lexical diversity.
* WatME increases semantic entropy in the green list, boosting expressiveness.
* Theorem: WatME is more likely than Vanilla to sample an “appropriate word.”

---

Experiments

Setup

* Models: Llama2-7B (unaligned), Vicuna-7B (aligned).
* Tasks:

  * Knowledge: TruthfulQA (truthful and informative answers).
  * Reasoning: GSM8K (math reasoning).
  * Fluency: C4 Perplexity.
* Metrics: Accuracy, AUROC, PPL, Truth × Info.

Key Results

| Model/Method    | GSM8K Accuracy | Truth × Info | AUROC Detection | Perplexity |
| --------------- | -------------- | ------------ | --------------- | ---------- |
| Llama2 baseline | 11.22%         | 88.23        | -               | 4.77       |
| +Vanilla        | ↓50.0%         | ↓45.4%       | 0.972           | ↑7.00      |
| +WatME (prompt) | ↓48.0%         | ↓42.9%       | 0.972           | ↑6.89      |
| +WatME (dict)   | ↓18.3%         | ↓30.7%       | 0.980           | ↑5.32      |

* WatME preserves emergent abilities better than Vanilla while maintaining detection performance.
* Prompt-based clustering favors informativeness, while dictionary-based favors semantic consistency.

---

System Mechanism

Robustness

* Tested under substitution attacks and paraphrasing attacks:

  * WatME remains more robust (still detectable).
  * Mutual exclusion reduces red-green flipping probability.
  * Cluster-based logic makes reverse-engineering harder.

Detection

* Uses z-score and AUROC for watermark detection.
* Increasing δ boosts detectability but affects quality.
* WatME consistently outperforms Vanilla across all δ settings, with higher detection curves.

---

Limitations

* Still not fully lossless (δ ≠ 0).
* Only tested in English.
* Low-entropy tasks (e.g., commonsense QA) pose robustness challenges.
* Prompt-based clustering quality depends on LLM sensitivity.

for our research:

WatME method synonym grouping red/green, mutual exclusion green + δ bias preserve expression space Visual analogy perceptual or task-equivalent elements grouped red/green mutual exclusion green + δ watermark keep quality

Redundancy types: - Appearance redundancy palette texture noise seed style vector - Geometric redundancy slight deformation LoD variants equivalent mesh fragments - Rendering redundancy lighting direction intensity color temperature camera trajectory perturbation anti-aliasing denoising settings - Feature redundancy VQ codebook tokens tri-plane voxel clusters attention head choices

Embedding only bias green logits with δ red untouched outputs statistically skew to green detectable signal keep equivalent options minimal quality loss
Detection reconstruct red/green via key count actual green hits vs random baseline z-score or AUROC significantly higher → watermark present
